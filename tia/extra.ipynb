{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# all the extra code that we don't need in main project but may come in use in future"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#this code is used to get a txt file from the internet in order to convert it to a csv file\n",
    "#txt file contains geoids associated with each county\n",
    "#we need geoids so we can merge it into our df\n",
    "#we need to do that because to use geopandas, we need some sort of common column to associate the location of a county with the county itself\n",
    "#\"easiest\" (the most mentally sane) way is by using a geoid\n",
    "\n",
    "import requests\n",
    "\n",
    "url = \"https://www2.census.gov/geo/docs/reference/county_adjacency/county_adjacency2023.txt\"\n",
    "response = requests.get(url)\n",
    "if response.status_code == 200:\n",
    "    with open(\"geoid.txt\", \"wb\") as file:\n",
    "        file.write(response.content)\n",
    "    geoid = pd.read_csv(\"geoid.txt\", delimiter=\"\\|\")\n",
    "    geoid.to_csv(\"geoid.csv\", index=False)\n",
    "    print(geoid)\n",
    "else: #just making sure it actually worked\n",
    "    print(\"fail\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#in geoid dataframe, there are a lot of repeats of rows (bc each row is a county that borders the main county)\n",
    "#removing the repeats (\"~\" is like \"!=\") and the extra territories\n",
    "\n",
    "geoid = geoid[~geoid.duplicated(subset='County GEOID', keep='first')].reset_index()\n",
    "geoid[\"state\"] = geoid[\"County Name\"].str[-2:]\n",
    "extraStates = [\"AS\", \"GU\", \"PR\", \"MP\", \"VI\"]\n",
    "geoid = geoid.drop(geoid[geoid[\"state\"].isin(extraStates)].index)\n",
    "geoid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#nice thing about this geoid dataframe is that it has the same number of rows as df (bc both demo and geoid come from the us census)\n",
    "#now we need to ensure the order of the counties in both is the same (which it should be bc they come from the same source)\n",
    "\n",
    "#this is just test code to make sure that \n",
    "#select rows where values of 'county_x' in df contain values of 'county name' in geoid\n",
    "#used to ensure that the counties match up (they do!!)\n",
    "selected_rows = geoid[geoid['County Name'].apply(lambda x: any(item in x for item in df['COUNTY_x']))]\n",
    "selected_rows #shows 3144 rows, meaning the counties match\n",
    "\n",
    "wrong = geoid[~geoid['County Name'].apply(lambda x: any(item in x for item in df['COUNTY_x']))]\n",
    "wrong #shows 0 rows, meaning that no counties mismatch\n",
    "\n",
    "#GEOID in the shapefile is in the datatype String but is int in geoid, so we are just converting it to string\n",
    "geoid[\"GEOID\"] = geoid[\"County GEOID\"].astype(str)\n",
    "\n",
    "#in shapefile, it is 5 digits, so if the geoid is \"1002\", the format of the data value is \"01002\"\n",
    "#this ensures all the values in our geoid df are formatted to have 0 in front if it has 4 digits to make it have 5 digits\n",
    "def add_zero(value):\n",
    "    if len(value) == 4:\n",
    "        return '0' + value\n",
    "    else:\n",
    "        return value\n",
    "geoid['GEOID'] = geoid['GEOID'].apply(add_zero)\n",
    "\n",
    "#only want GEOID column\n",
    "geoidFinal = geoid[[\"GEOID\"]]\n",
    "geoidFinal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#now we merge geoid with df to create a df_with_geoid that has all the necessary data together\n",
    "df_with_geoid = pd.merge(df, geoidFinal, left_index=True, right_index=True)\n",
    "df_with_geoid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#using geopandas, we create an empty geospatial viz\n",
    "gdf = gpd.read_file(\"cb_2018_us_county_500k.shp\")\n",
    "\n",
    "#merging our df_with_geoid and the empty geospatial viz\n",
    "merged = gdf.merge(df_with_geoid, on='GEOID', how='left')\n",
    "\n",
    "#filtering out extra\n",
    "territory_statefps = [\"72\", \"60\", \"69\", \"78\", \"66\"]\n",
    "merged_gdf = merged[~merged['STATEFP'].isin(territory_statefps)]\n",
    "\n",
    "col_name = \"RISK_SCORE\"\n",
    "\n",
    "#plotting specifically data in a column (i chose risk_score just to test)\n",
    "us = merged_gdf.plot(column=col_name, cmap='OrRd', legend=True, figsize=(12, 8))\n",
    "title = col_name + ' by County'\n",
    "plt.title(title)\n",
    "\n",
    "#set the extent to focus on the US\n",
    "#main part of US is [-130,-65]x[24,50]\n",
    "us.set_xlim([-180, -65])  \n",
    "us.set_ylim([17, 75])    \n",
    "\n",
    "#uncomment to see\n",
    "plt.show()\n",
    "\n",
    "#how do we know we're looking at correct code!!???\n",
    "#when you go to the nri national map (https://hazards.fema.gov/nri/map) it shows the same map, just colors are diff :D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#manually set the center and zoom level to cover the entire United States\n",
    "center = [45, -135]\n",
    "zoom_level = 3\n",
    "\n",
    "#create a Folium map centered around the entire United States\n",
    "interactiveMap = folium.Map(location=center, zoom_start=zoom_level)\n",
    "\n",
    "#add a choropleth layer for risk\n",
    "folium.Choropleth(\n",
    "    geo_data=merged_gdf,\n",
    "    data=merged_gdf,\n",
    "    columns=[\"NAME\", 'RISK_SCORE'],\n",
    "    key_on='feature.properties.NAME',\n",
    "    fill_color='YlOrRd',\n",
    "    fill_opacity=0.7,\n",
    "    line_opacity=0.2,\n",
    "    line_weight=1,\n",
    "    legend_name='Risk Level',\n",
    "    nan_fill_color='gray',  # gray places are NaN values\n",
    "    nan_fill_opacity=0.4\n",
    ").add_to(interactiveMap)\n",
    "\n",
    "#add GeoJson layer with hover information\n",
    "folium.GeoJson(\n",
    "    merged_gdf,\n",
    "    style_function=lambda feature: {\n",
    "        'fillColor': 'transparent',  #set fill color to transparent\n",
    "        'color': 'transparent',  #set border color to transparent\n",
    "        'weight': 0,  #set border weight to 0\n",
    "        'dashArray': '5, 5',\n",
    "        'fillOpacity': 0.7 \n",
    "    },\n",
    "    highlight_function=lambda x: {'fillColor': 'lightblue', 'color': 'lightblue'},\n",
    "    tooltip=folium.features.GeoJsonTooltip( #example fields, will change this later\n",
    "        fields=[\"GEOID\", 'NAME', 'STATE_x', 'RISK_SCORE', 'PERCENT_WHITE', 'PERCENT_BLACK', 'PERCENT_ASIAN'],\n",
    "        aliases=[\"GeoID\", 'County', 'State', 'Risk Score', 'Percent White', 'Percent Black', 'Percent Asian'],\n",
    "        localize=True\n",
    "    )\n",
    ").add_to(interactiveMap)\n",
    "\n",
    "#display the map (it won't let me upload file without commenting this out)\n",
    "#interactiveMap\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#check for NaN values in the 'RISK_SCORE' column\n",
    "missing_data = merged_gdf[merged_gdf['RISK_SCORE'].isna()]\n",
    "value_counts = missing_data['STATEFP'].value_counts()\n",
    "print(value_counts)\n",
    "\n",
    "#ok so these are the nan values\n",
    "#02 = alaska\n",
    "#09 = connecticut (fuck connecticut)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#social vulnerability index??\n",
    "#it relates to race https://www.atsdr.cdc.gov/placeandhealth/svi/index.html\n",
    "svi = pd.read_csv(\"SVI_2020_US_county.csv\")\n",
    "svi\n",
    "#if we even have time we could try and look at this as well"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
